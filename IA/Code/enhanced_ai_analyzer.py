"""
Analyseur IA amÃ©liorÃ© avec interface Ollama locale
Fichier : enhanced_ai_analyzer.py
"""
import requests
import json
import webbrowser
from config import (
    get_ollama_url, get_ollama_web_url,
    OLLAMA_MODEL, AI_TIMEOUT, MAX_TOKENS,
    ANTHROPIC_API_KEY, OPENAI_API_KEY, GROQ_API_KEY
)


class EnhancedAIAnalyzer:
    """Analyseur IA avec prioritÃ© sur Ollama local"""
    
    def __init__(self, log_callback=None):
        self.log_callback = log_callback
        self.ollama_api_url = get_ollama_url()
        self.ollama_web_url = get_ollama_web_url()
        self.ollama_available = False
        self.available_models = []
    
    def log(self, message):
        """Log un message"""
        if self.log_callback:
            try:
                self.log_callback(message)
            except:
                print(message)
        else:
            print(message)
    
    def check_ollama_endpoints(self):
        """VÃ©rifie la disponibilitÃ© d'Ollama et liste les modÃ¨les"""
        self.log("\nğŸ” VÃ‰RIFICATION OLLAMA")
        self.log("=" * 80)
        
        # VÃ©rifier API
        try:
            self.log(f"  ğŸ“¡ Test API: {self.ollama_api_url}")
            response = requests.get(
                f"{self.ollama_api_url}/api/tags",
                timeout=5
            )
            
            if response.status_code == 200:
                data = response.json()
                self.available_models = [model['name'] for model in data.get('models', [])]
                self.ollama_available = True
                
                self.log(f"  âœ… API Ollama accessible")
                self.log(f"  ğŸ“¦ ModÃ¨les disponibles: {len(self.available_models)}")
                
                for model in self.available_models:
                    icon = "ğŸ¤–" if model == OLLAMA_MODEL else "  "
                    self.log(f"     {icon} {model}")
                
                if OLLAMA_MODEL in self.available_models:
                    self.log(f"  âœ“ ModÃ¨le configurÃ© '{OLLAMA_MODEL}' trouvÃ©")
                else:
                    self.log(f"  âš ï¸  ModÃ¨le '{OLLAMA_MODEL}' non trouvÃ©, utilisation du premier disponible")
            else:
                self.log(f"  âŒ API rÃ©pond avec code {response.status_code}")
        
        except requests.exceptions.ConnectionError:
            self.log(f"  âŒ Impossible de se connecter Ã  l'API")
        except Exception as e:
            self.log(f"  âŒ Erreur: {str(e)}")
        
        # VÃ©rifier interface web
        try:
            self.log(f"\n  ğŸŒ Test interface web: {self.ollama_web_url}")
            response = requests.get(self.ollama_web_url, timeout=3)
            
            if response.status_code == 200:
                self.log(f"  âœ… Interface web accessible")
                self.log(f"  ğŸ’¡ Ouvrir dans le navigateur: {self.ollama_web_url}")
            else:
                self.log(f"  âš ï¸  Interface web rÃ©pond avec code {response.status_code}")
        
        except:
            self.log(f"  âš ï¸  Interface web non accessible")
        
        # RÃ©sumÃ©
        self.log("=" * 80)
        if self.ollama_available:
            self.log("âœ… Ollama opÃ©rationnel - Analyses locales activÃ©es\n")
        else:
            self.log("âš ï¸  Ollama indisponible - Utilisation des API externes\n")
    
    def get_working_model(self):
        """Retourne le modÃ¨le Ã  utiliser"""
        if OLLAMA_MODEL in self.available_models:
            return OLLAMA_MODEL
        elif self.available_models:
            return self.available_models[0]
        return OLLAMA_MODEL
    
    def open_ollama_web(self):
        """Ouvre l'interface web Ollama dans le navigateur"""
        try:
            webbrowser.open(self.ollama_web_url)
            self.log(f"ğŸŒ Interface Ollama ouverte: {self.ollama_web_url}")
            return True
        except Exception as e:
            self.log(f"âŒ Impossible d'ouvrir l'interface: {e}")
            return False
    
    def analyze_with_ollama(self, prompt):
        """Analyse avec Ollama local"""
        if not self.ollama_available:
            return None
        
        try:
            model = self.get_working_model()
            self.log(f"  ğŸ¤– Analyse avec Ollama ({model})...")
            
            response = requests.post(
                f'{self.ollama_api_url}/api/generate',
                json={
                    'model': model,
                    'prompt': prompt,
                    'stream': False,
                    'options': {
                        'temperature': 0.7,
                        'num_predict': MAX_TOKENS
                    }
                },
                timeout=AI_TIMEOUT
            )
            
            if response.status_code == 200:
                result = response.json().get('response', '')
                if result:
                    self.log("  âœ… Analyse Ollama rÃ©ussie")
                    return result
                else:
                    self.log("  âš ï¸  RÃ©ponse Ollama vide")
            else:
                self.log(f"  âš ï¸  Ollama erreur HTTP {response.status_code}")
        
        except requests.exceptions.Timeout:
            self.log(f"  âš ï¸  Ollama timeout aprÃ¨s {AI_TIMEOUT}s")
        except requests.exceptions.ConnectionError:
            self.log(f"  âš ï¸  Ollama connexion perdue")
            self.ollama_available = False
        except Exception as e:
            self.log(f"  âš ï¸  Ollama erreur: {e}")
        
        return None
    
    def analyze_with_claude(self, prompt):
        """Analyse avec Claude API (fallback)"""
        if not ANTHROPIC_API_KEY:
            return None
        
        try:
            self.log("  ğŸ¤– Tentative analyse avec Claude API...")
            response = requests.post(
                'https://api.anthropic.com/v1/messages',
                headers={
                    'x-api-key': ANTHROPIC_API_KEY,
                    'anthropic-version': '2023-06-01',
                    'content-type': 'application/json'
                },
                json={
                    'model': 'claude-sonnet-4-20250514',
                    'max_tokens': MAX_TOKENS,
                    'messages': [{'role': 'user', 'content': prompt}]
                },
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()['content'][0]['text']
                self.log("  âœ… Analyse Claude rÃ©ussie")
                return result
        except Exception as e:
            self.log(f"  âš ï¸  Claude API erreur: {e}")
        return None
    
    def analyze_with_openai(self, prompt):
        """Analyse avec OpenAI API (fallback)"""
        if not OPENAI_API_KEY:
            return None
        
        try:
            self.log("  ğŸ¤– Tentative analyse avec OpenAI...")
            response = requests.post(
                'https://api.openai.com/v1/chat/completions',
                headers={
                    'Authorization': f'Bearer {OPENAI_API_KEY}',
                    'Content-Type': 'application/json'
                },
                json={
                    'model': 'gpt-4o-mini',
                    'messages': [{'role': 'user', 'content': prompt}],
                    'max_tokens': MAX_TOKENS
                },
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()['choices'][0]['message']['content']
                self.log("  âœ… Analyse OpenAI rÃ©ussie")
                return result
        except Exception as e:
            self.log(f"  âš ï¸  OpenAI API erreur: {e}")
        return None
    
    def analyze_with_groq(self, prompt):
        """Analyse avec Groq API (fallback)"""
        if not GROQ_API_KEY:
            return None
        
        try:
            self.log("  ğŸ¤– Tentative analyse avec Groq...")
            response = requests.post(
                'https://api.groq.com/openai/v1/chat/completions',
                headers={
                    'Authorization': f'Bearer {GROQ_API_KEY}',
                    'Content-Type': 'application/json'
                },
                json={
                    'model': 'llama-3.3-70b-versatile',
                    'messages': [{'role': 'user', 'content': prompt}],
                    'max_tokens': MAX_TOKENS
                },
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()['choices'][0]['message']['content']
                self.log("  âœ… Analyse Groq rÃ©ussie")
                return result
        except Exception as e:
            self.log(f"  âš ï¸  Groq API erreur: {e}")
        return None
    
    def build_prompt(self, event, web_results=None):
        """Construit le prompt d'analyse optimisÃ©"""
        # DÃ©terminer le type d'appareil
        device_type = "Windows Server"
        if event.get('_is_syslog'):
            device_type = f"{event.get('_device_name', 'Ã‰quipement rÃ©seau')} ({event.get('_device_type', 'network')})"
        
        prompt = f"""Tu es un expert en sÃ©curitÃ© informatique et administration systÃ¨me. Analyse cette erreur et fournis une solution concrÃ¨te et actionnable.

CONTEXTE DE L'INCIDENT:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Type d'appareil: {device_type}
Source: {event['source']}
Event ID: {event['event_id']}
Type d'erreur: {event['event_type']}
Ordinateur/IP: {event['computer']}
Horodatage: {event['time_generated']}
PrioritÃ©: {event.get('_priority', 5)}/10

MESSAGE D'ERREUR:
{event['message'][:800]}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

        if web_results:
            prompt += f"""
INFORMATIONS TROUVÃ‰ES SUR LE WEB:
{web_results[:1500]}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

        prompt += """
FOURNIS UNE ANALYSE STRUCTURÃ‰E ET DÃ‰TAILLÃ‰E:

ğŸ” 1. DIAGNOSTIC
   â€¢ Explication claire du problÃ¨me en 2-3 phrases
   â€¢ Impact sur le systÃ¨me/rÃ©seau
   â€¢ Niveau de gravitÃ© rÃ©el

ğŸ¯ 2. CAUSES PROBABLES
   â€¢ Liste de 2-3 causes possibles avec leurs probabilitÃ©s
   â€¢ Contexte technique de chaque cause

âš¡ 3. SOLUTION IMMÃ‰DIATE (< 5 minutes)
   â€¢ Actions Ã  faire MAINTENANT pour contenir le problÃ¨me
   â€¢ Ã‰tapes numÃ©rotÃ©es et prÃ©cises
   â€¢ Commandes exactes si applicable

ğŸ› ï¸ 4. RÃ‰SOLUTION COMPLÃˆTE (solution durable)
   â€¢ ProcÃ©dure dÃ©taillÃ©e pas Ã  pas
   â€¢ Commandes PowerShell/CMD si nÃ©cessaire
   â€¢ Configuration Ã  modifier
   â€¢ VÃ©rifications Ã  effectuer

ğŸ”’ 5. PRÃ‰VENTION
   â€¢ Mesures pour Ã©viter la rÃ©currence
   â€¢ Bonnes pratiques Ã  mettre en place
   â€¢ Monitoring recommandÃ©

IMPORTANT: 
- Sois TRÃˆS prÃ©cis et technique
- Fournis des commandes EXACTES et testÃ©es
- Adapte-toi au type d'appareil (serveur Windows ou Ã©quipement rÃ©seau)
- Priorise la SÃ‰CURITÃ‰ et la STABILITÃ‰
- RÃ©ponds en FRANÃ‡AIS

Commence ton analyse maintenant:"""

        return prompt
    
    def analyze(self, event, web_results=None):
        """Analyse l'erreur avec cascade de providers (Ollama prioritaire)"""
        prompt = self.build_prompt(event, web_results)
        
        # PRIORITÃ‰ 1: Ollama local (plus rapide et privÃ©)
        if self.ollama_available:
            result = self.analyze_with_ollama(prompt)
            if result:
                return result
        
        # FALLBACK: APIs externes
        self.log("  âš ï¸  Ollama indisponible, utilisation des API externes...")
        
        providers = [
            ('Groq', self.analyze_with_groq),
            ('Claude', self.analyze_with_claude),
            ('OpenAI', self.analyze_with_openai)
        ]
        
        for name, func in providers:
            result = func(prompt)
            if result:
                return result
        
        # Si aucune IA n'a fonctionnÃ©
        self.log("  âš ï¸  Aucune IA disponible, analyse basique")
        return self.fallback_analysis(event)
    
    def fallback_analysis(self, event):
        """Analyse de secours si aucune IA n'est disponible"""
        return f"""ğŸ” DIAGNOSTIC:
Erreur dÃ©tectÃ©e - Event ID {event['event_id']} depuis {event['source']}
Aucun service d'analyse IA n'est actuellement disponible.

ğŸ¯ ANALYSE AUTOMATIQUE:
Cette erreur nÃ©cessite une investigation manuelle. Voici quelques pistes:

âš¡ ACTIONS IMMÃ‰DIATES RECOMMANDÃ‰ES:
1. Consulter l'Observateur d'Ã©vÃ©nements Windows pour plus de dÃ©tails
2. Rechercher "Event ID {event['event_id']} {event['source']}" sur Google
3. VÃ©rifier les logs complets de l'application concernÃ©e
4. Consulter la documentation Microsoft ou du fabricant

ğŸ› ï¸ RESSOURCES UTILES:
â€¢ Event ID Database: https://www.eventid.net/search.asp?evtid={event['event_id']}
â€¢ Microsoft Docs: https://docs.microsoft.com/windows/
â€¢ TechNet Forums: https://social.technet.microsoft.com/

ğŸ”’ RECOMMANDATIONS:
1. DÃ©marrez Ollama pour obtenir des analyses IA dÃ©taillÃ©es:
   - API: {self.ollama_api_url}
   - Interface: {self.ollama_web_url}
   
2. Ou configurez une clÃ© API externe:
   - Anthropic Claude (ANTHROPIC_API_KEY)
   - OpenAI GPT (OPENAI_API_KEY)
   - Groq (GROQ_API_KEY)

ğŸ’¡ CONSEIL:
Pour des analyses prÃ©cises et rapides, assurez-vous qu'Ollama est dÃ©marrÃ©
avec le modÃ¨le '{OLLAMA_MODEL}' installÃ©.
"""
    
    def test_analysis(self):
        """Test rapide de l'analyseur"""
        self.log("\nğŸ§ª TEST DE L'ANALYSEUR IA")
        self.log("=" * 80)
        
        test_event = {
            'source': 'Test',
            'event_id': 4625,
            'event_type': 'ERROR',
            'computer': 'TEST-PC',
            'time_generated': '2025-01-07 10:00:00',
            'message': 'Test de connexion Ã©chouÃ©e',
            '_priority': 8
        }
        
        result = self.analyze(test_event)
        
        if result and len(result) > 100:
            self.log("âœ… Test rÃ©ussi - Analyseur opÃ©rationnel")
            self.log(f"   Longueur de la rÃ©ponse: {len(result)} caractÃ¨res")
            return True
        else:
            self.log("âŒ Test Ã©chouÃ© - VÃ©rifiez la configuration IA")
            return False